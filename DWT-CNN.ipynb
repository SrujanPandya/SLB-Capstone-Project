{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### DWT Preprocessing"
      ],
      "metadata": {
        "id": "cL_H486dFd87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywavelets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Txkg_8LQFjp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pywt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "mw182i54yZei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dwt_transform(image):\n",
        "    coeffs2 = pywt.dwt2(image, 'haar')  # DWT using Haar wavelet\n",
        "    cA, (cH, cV, cD) = coeffs2\n",
        "    return np.stack([cA, cH, cV, cD], axis=1)  # Stacked into a single 4-channel array\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_and_save_image(image_path, output_path):\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image = np.array(image)\n",
        "    dwt_image = dwt_transform(image)\n",
        "    np.save(output_path, dwt_image)  # Saved as .npy\n",
        "\n",
        "original_image_folder = '/content/drive/MyDrive/UBI_images/amplitude_dynamic'\n",
        "npy_output_folder = '/content/drive/MyDrive/UBI_images/train'\n",
        "\n",
        "if not os.path.exists(npy_output_folder):\n",
        "    os.makedirs(npy_output_folder)\n",
        "\n",
        "for image_file in os.listdir(original_image_folder):\n",
        "    if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
        "        input_image_path = os.path.join(original_image_folder, image_file)\n",
        "        output_npy_path = os.path.join(npy_output_folder, f\"{os.path.splitext(image_file)[0]}.npy\")\n",
        "        preprocess_and_save_image(input_image_path, output_npy_path)\n",
        "\n",
        "print(f\"Processed and saved {len(os.listdir(npy_output_folder))} images as .npy files.\")"
      ],
      "metadata": {
        "id": "I4KQ7N4wDAR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder Architecture"
      ],
      "metadata": {
        "id": "5UNRhPCBFZH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMSf1bGHnA2M"
      },
      "outputs": [],
      "source": [
        "class DWT_Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DWT_Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Upsample layer to match output dimensions\n",
        "        self.upsample = nn.Upsample(size=(90, 90), mode = 'bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = self.upsample(decoded)\n",
        "        return decoded\n",
        "\n",
        "dummy_input = torch.randn(16, 4, 90, 90) # Batch of 16, 4 channels, 90x90 images\n",
        "model = DWT_Autoencoder()\n",
        "\n",
        "output = model(dummy_input)\n",
        "print(f\"Output size: {output.size()}\") # Check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Data Preparation"
      ],
      "metadata": {
        "id": "zifHSZklFsuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DWTAutoencoderDataset(Dataset):\n",
        "    def __init__(self, image_folder, normalize=True):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.npy')]\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      image_path = self.image_paths[idx]\n",
        "      if not image_path.endswith('.npy'):\n",
        "        dwt_image = preprocess_and_save_image(image_path)\n",
        "        np.save(image_path.replace('.png', '.npy'), dwt_image)\n",
        "      else:\n",
        "        dwt_image = np.load(image_path, allow_pickle=True)\n",
        "\n",
        "      if self.normalize:\n",
        "        dwt_image = dwt_image / np.max(dwt_image)  # Normalize to [0, 1]\n",
        "      return torch.tensor(dwt_image, dtype=torch.float32)\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        dwt_image = np.load(image_path, allow_pickle=True)\n",
        "        return dwt_image\n",
        "\n",
        "image_folder = '/content/drive/MyDrive/UBI_images/train'\n",
        "train_dataset = DWTAutoencoderDataset(image_folder, normalize=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Check\n",
        "print(f\"Number of images: {len(train_dataset)}\")"
      ],
      "metadata": {
        "id": "0UbEzw5zFtDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Autoencoder"
      ],
      "metadata": {
        "id": "iqdOX0OoHS0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DWT_Autoencoder().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# criterion = nn.MSELoss() # Mean-Squared Loss\n",
        "criterion = nn.SmoothL1Loss()  # Huber Loss\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "\n",
        "        data = data.permute(0, 2, 1, 3)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"dwt_autoencoder.pth\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0eZGc9eTHTGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruction with DWT"
      ],
      "metadata": {
        "id": "VdhIczEfHWT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pywt\n",
        "\n",
        "def inverse_dwt(coeffs):\n",
        "    cA, (cH, cV, cD) = coeffs\n",
        "    return pywt.idwt2((cA, (cH, cV, cD)), 'haar')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "\n",
        "        print(f\"Raw data shape: {data.shape}\")\n",
        "        data = data.permute(0, 2, 1, 3)\n",
        "        print(f\"Permuted data shape: {data.shape}\")\n",
        "        data = torch.clamp(data, min=0, max=1)\n",
        "\n",
        "        reconstructed_dwt = model(data)\n",
        "        print(f\"Reconstructed DWT Shape: {reconstructed_dwt.shape}\") # Checking\n",
        "\n",
        "        reconstructed_dwt = reconstructed_dwt.cpu().numpy()\n",
        "\n",
        "        reconstructed_images = []\n",
        "\n",
        "        for i in range(reconstructed_dwt.shape[0]):\n",
        "            coeffs = (reconstructed_dwt[i, 0], (reconstructed_dwt[i, 1], reconstructed_dwt[i, 2], reconstructed_dwt[i, 3]))\n",
        "            reconstructed_image = inverse_dwt(coeffs)\n",
        "            reconstructed_images.append(reconstructed_image)\n",
        "\n",
        "        # Convert reconstructed images list to a NumPy array for visualization\n",
        "        reconstructed_images = np.array(reconstructed_images)\n",
        "\n",
        "        # Visualization (for the first image in the batch)\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        ax[0].imshow(data[4].cpu().numpy().transpose(1, 2, 0))\n",
        "        ax[0].set_title(\"Original Image\")\n",
        "        ax[0].axis('off')\n",
        "\n",
        "        ax[1].imshow(reconstructed_images[4], cmap='gray')\n",
        "        ax[1].set_title(\"Reconstructed Image\")\n",
        "        ax[1].axis('off')\n",
        "\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "id": "U6-k6TpBHWow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reconstructed DWT Coefficients Shape: \", reconstructed_dwt.shape)"
      ],
      "metadata": {
        "id": "bt7ZeFhRVCga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}